# 📊 데이터사이언스 직무 채용 요건 분석 자동화

## 👥 팀원

| 이름 | 역할 |
|------|------|
| 최은혜 | 크롤링 개발, 자동화 파이프라인, 크롤링 스케쥴링 처리, 데이터 전처리, DB 설계, 워드 클라우드 생성 및 분석, NLP 기반 키워드 추출 및 분석, 전체적인 일정 관리, 노션 관리, 피피티제작, 깃허브 업로드 및 README 작성 |
| 노주원 | 크롤링 개발, 데이터 전처리, EDA 및 트렌드 분석, README 관리, 전체적인 업무 정리 |
| 최소은 | 크롤링 개발, 데이터 시각화, EDA, 트렌드 분석, 문서화, DB 설계 |
| 탁홍진 | 크롤링 개발, 데이터 시각화, EDA, 트렌드 분석, 문서화, DB 설계, 발표 |
---

## 📌 프로젝트 개요

본 프로젝트는 잡플래닛, 원티드, 점핏 등 국내 주요 채용 플랫폼에서 **데이터사이언스 관련 직무 채용 공고를 자동으로 수집**하고, **요구되는 자격 요건 및 우대사항을 분석**할 수 있는 시스템을 구축하는 것을 목표

채용 시장에서 요구되는 **기술 스택, 학력, 경력 등의 트렌드**를 파악함으로써, 구직자와 경력 개발자 모두에게 **실질적인 인사이트를 제공**할 수 있음

---

## 🎯 주요 목표

1. **채용 공고 크롤링 자동화**
   - 잡플래닛, 원티드, 점핏 사이트 대상
   - 직무별 크롤링: `"데이터사이언티스트"`, `"머신러닝"`, `"데이터 분석"`, `"DBA"` 등

2. **데이터 정제 및 통합**
   - 사이트별로 수집된 데이터를 하나의 통합된 형태로 구성
   - **중복 제거**, 불필요한 정보 제거, **핵심 스펙 항목 추출** (학력, 경력, 기술 스택 등)

3. **DB 저장 및 관리**
   - 정제된 데이터를 **MariaDB** 등 관계형 데이터베이스에 저장
   - 검색, 분석, 시각화가 용이하도록 테이블 구조 설계

4. **전체 파이프라인 자동화**
   - 일정 주기로 크롤링부터 저장까지 자동 수행
   - 로컬: Crontab / Windows Scheduler 사용
   - 클라우드 확장 고려: GitHub Actions, AWS Lambda 등

---

## 🔧 시스템 구성도
[크롤러 (Selenium / BeautifulSoup)]
↓
[데이터 정제 및 중복 제거 (Pandas)]
↓
[CSV → MariaDB 저장]
↓
[자동 실행 (크론탭 / 스케줄러)]


---

## 🧠 기대 효과

- **실제 채용 트렌드 파악**: 어떤 기술/스펙이 수요가 높은지 확인 가능  
- **커리어 설계 지원**: 학생 및 취업 준비생이 요구되는 능력을 사전에 준비 가능  
- **확장성**: 추후 시각화 대시보드, 연도별 리포트 생성 시스템으로 확장 가능

---

## 💡 사용 기술 스택

| 구분       | 기술/도구                         |
|------------|------------------------------------|
| 언어       | Python                             |
| 웹 크롤링  | Selenium, BeautifulSoup             |
| 데이터 처리| Pandas                             |
| DB         | MariaDB (with HeidiSQL)            |
| 자동화     | Crontab (Linux), Windows Scheduler |

---

## 🔄 향후 발전 방향

- **채용 트렌드 시각화 대시보드 구현**
- **자연어처리(NLP) 적용하여 키워드 자동 추출**
- **추가 사이트 확장 (사람인, 로켓펀치 등)**

